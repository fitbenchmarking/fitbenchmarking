@Article{mantid,
  Title                    = {Mantid-Data analysis and visualization package for neutron scattering and $\mu$SR experiments},
  Author                   = {Arnold, O. and Bilheux, J.C. and Borreguero, J.M. and Buts, A. and Campbell, S.I. and Chapon, L. and Doucet, M. and Draper, N. and Ferraz Leal, R. and Gigg, M.A. and et al.},
  Journal                  = {Nuclear Instruments and Methods in Physics Research Section A},
  Year                     = {2014},

  Month                    = {November},
  Note                     = {www.mantidproject.org},
  Pages                    = {156-166},
  Volume                   = {764},

  Owner                    = {trees},
  Timestamp                = {2017.01.17},
  Url                      = {www.mantidproject.org}
}

@article{cutest,
author = {Gould, Nicholas I. and Orban, Dominique and Toint, Philippe L.},
title = {{CUTEst: A Constrained and Unconstrained Testing Environment with Safe Threads for Mathematical Optimization}},
year = {2015},
issue_date = {April     2015},
publisher = {Kluwer Academic Publishers},
address = {USA},
volume = {60},
number = {3},
issn = {0926-6003},
url = {https://doi.org/10.1007/s10589-014-9687-3},
doi = {10.1007/s10589-014-9687-3},
abstract = {We describe the most recent evolution of our constrained and unconstrained testing environment and its accompanying SIF decoder. Code-named SIFDecode and CUTEst, these updated versions feature dynamic memory allocation, a modern thread-safe Fortran modular design, a new Matlab interface and a revised installation procedure integrated with GALAHAD.},
journal = {Comput. Optim. Appl.},
month = apr,
pages = {545–557},
numpages = {13},
keywords = {Benchmarking, CUTE, CUTEr, Modeling, CUTEst, Optimization}
}





@software{sasview,
  author       = {Doucet, Mathieu and
                  Cho, Jae Hie and
                  Alina, Gervaise and
                  Attala, Ziggy and
                  Bakker, Jurrian and
                  Bouwman, Wim and
                  Butler, Paul and
                  Campbell, Kieran and
                  Cooper-Benun, Torin and
                  Durniak, Celine and
                  Forster, Laura and
                  Gonzales, Miguel and
                  Heenan, Richard and
                  Jackson, Andrew and
                  King, Stephen and
                  Kienzle, Paul and
                  Krzywon, Jeff and
                  Nielsen, Torben and
                  O'Driscoll, Lewis and
                  Potrzebowski, Wojciech and
                  Prescott, Stewart and
                  Ferraz Leal, Ricardo and
                  Rozycko, Piotr and
                  Snow, Tim and
                  Washington, Adam},
  title        = {SasView version 5.0.3},
  month        = jul,
  year         = 2020,
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.3930098},
  url          = {https://doi.org/10.5281/zenodo.3930098}
}

@book{gsl,
  author = {Galassi, M. and Davies, J. and Theiler, J. and Gough, B. and Jungman, G. and Alken, P. and Booth, M. and Rossi, F.},
  edition = {Third},
  editor = {Gough, B.},
  publisher = {Network Theory Ltd.},
  title = {GNU Scientific Library Reference Manual },
  isbn = {0954612078},
  year = 2009
}

@misc{olympus,
      title={Olympus: a benchmarking framework for noisy optimization and experiment planning}, 
      author={Florian Häse and Matteo Aldeghi and Riley J. Hickman and Loïc M. Roch and Melodie Christensen and Elena Liles and Jason E. Hein and Alán Aspuru-Guzik},
      year={2021},
      eprint={2010.04153},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{paver,
  title = {{{PAVER}} 2.0: An Open Source Environment for Automated Performance Analysis of Benchmarking Data},
  shorttitle = {{{PAVER}} 2.0},
  author = {Bussieck, Michael R. and Dirkse, Steven P. and Vigerske, Stefan},
  year = {2014},
  month = jul,
  volume = {59},
  pages = {259--275},
  issn = {0925-5001, 1573-2916},
  doi = {10.1007/s10898-013-0131-5},
  abstract = {In this paper we describe PAVER 2.0, an environment (i.e. a process and a suite of tools supporting that process) for the automated performance analysis of benchmarking data. This new environment improves on its predecessor by addressing some of the shortcomings of the original PAVER [6] and extending its capabilities. The changes serve to further the original goals of PAVER (automation of the visualization and summarization of benchmarking data) while making the environment more accessible for the use of and modification by the entire community of potential users. In particular, we have targeted the end-users of optimization software, as they are best able to make the many subjective choices necessary to produce impactful results when benchmarking optimization software. We illustrate with some sample analyses conducted via PAVER 2.0.},
  file = {C\:\\Users\\dgk98065\\Zotero\\storage\\HHCECWGY\\Bussieck et al. - 2014 - PAVER 2.0 an open source environment for automate.pdf},
  journal = {Journal of Global Optimization},
  language = {en},
  number = {2-3}
}

@misc{benchopt,
  title = {BenchOpt 1.1.0},
  howpublished = {\url{https://benchopt.github.io}},
  note = {Accessed: 2021-07-04},
  year = {2021}
}
